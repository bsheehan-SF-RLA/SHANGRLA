{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONEAudit Demo\n",
    "\n",
    "ONEAudit (Refereed paper: https://link.springer.com/chapter/10.1007/978-3-031-48806-1_5 Full version: https://arxiv.org/abs/2303.03335 ) is a way to use batch tally information efficiently in RLAs. \n",
    "It is vastly more efficient than batch-level comparison auditing.\n",
    "For each SHANGRLA assertion, ONEAudit creates an \"average\" assorter value for each reporting batch.\n",
    "That is then used in a ballot-level comparison audit based on comparing the assorter applied to the manually ascertained vote (MVR, manual vote record) on each ballot card the audit selects to the average assorter value for the batch to which each ballot belongs.\n",
    "\n",
    "ONEAudit is useful in a variety of situations, including:\n",
    "\n",
    "+ when batch tallies are available, whether or not the batches correspond to physical batches, in contrast to traditional batch-level comparison audits, which work only when reporting batches correspond to physical batches\n",
    "+ when CVRs are available for batches of cards but there is no mapping from individual cards to individual CVRs (this is common for precinct-count optical scan systems)\n",
    "+ when CVRs are available for some cards but not others (ONEAudit improves on SUITE in that situation, avoiding the need for stratification)\n",
    "\n",
    "`SHANGRLA` currently infers batch information from Dominion CVRs as currently (that is, as of August 2024) used by San Francisco, as follows:\n",
    "\n",
    "+ when reading the CVRs using `shangrla.formats.Dominion.read_cvrs()`, set `pool_groups` to be the list of `CountingGroupID`s that should be audited using ONEAudit CVRs derived from batch tallies.\n",
    "    - For SF, that is `CountingGroupID == 1`.\n",
    "    - if `pool_groups` is nonempty, the CVRs with `CountingGroupID in pool_groups` are marked as `pool`\n",
    "+ apply `shangrla.core.Audit.CVR.check_tally_pools()`: ensure every CVR in each `tally_pool` has the same value of `pool`\n",
    "+ apply`shangrla.core.Audit.CVR.add_pool_contests()`: ensure every CVR in each `tally_pool` for which `pool == True` has every contest in the tally_pool\n",
    "+ create the assertions for the contests under audit using functions in `shangrla.core.Audit.Assertion`\n",
    "+ apply `shangrla.core.Audit.Assorter.set_tally_pool_means()` to set the assorter means\n",
    "+ estimate initial sample size\n",
    "+ audit then proceeds as a standard ballot-level comparison audit. The MVR for each inspected card will automatically be compared to the ONEAudit CVRs for the batch to which that card belongs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow for a ONEAudit RLA\n",
    "\n",
    "+ Read overall audit information (including the seed) and contest information\n",
    "+ Read RAIRE assertions for IRV contests and construct assertions for all other contests\n",
    "+ Read ballot manifest\n",
    "+ For comparison audits, read cvrs. Every CVR should have a corresponding manifest entry. Set `pool` and `pool_group` for each CVR that contributes to a ONEAudit pooled CVR.\n",
    "+ Prepare ~2EZ:\n",
    "    - `N_phantoms = max_cards - cards_in_manifest`\n",
    "    - If `N_phantoms < 0`: complain\n",
    "    - Else: create `N_phantoms` phantom cards\n",
    "    - For each contest `c`:\n",
    "        + `N_c` is the input upper bound on the number of cards that contain `c`\n",
    "        + If `N_c is None`: `N_c = max_cards - non_c_cvrs`, where `non_c_cvrs` is #CVRs that don't contain `c`\n",
    "        + `C_c` is the number of CVRs that contain the contest\n",
    "        + If `C_c > N_c`: complain\n",
    "        + Else if `N_c - C_c > N_phantoms`: complain\n",
    "        + Else:\n",
    "            - Consider contest `c` to be on the first `N_c - C_c` phantom CVRs\n",
    "            - Consider contest `c` to be on the first `N_c - C_c` phantom ballots\n",
    "+ Create Assertions for every Contest. This involves also creating an Assorter for every Assertion, and a `NonnegMean` test\n",
    "for every Assertion.\n",
    "+ Calculate assorter margins for all assorters:\n",
    "    - If `not use_style`: apply the Assorter to all cards and CVRs, including phantoms\n",
    "    - Else: apply the assorter only to cards/cvrs reported to contain the contest, including phantoms that contain the contest\n",
    "+ Create ONEAudit CVRs for groups of CVRs that should be pooled.\n",
    "+ Set `assertion.test.u` to the appropriate value for each assertion: `assorter.upper_bound` for polling audits or \n",
    "      `2/(2-assorter.margin/assorter.upper_bound)` for ballot-level comparison audits\n",
    "+ Estimate starting sample size for the specified sampling design (w/ or w/o replacement, stratified, etc.), for chosen risk function, use of card-style information, etc.:\n",
    "    - User-specified criterion, controlled by parameters. Examples:\n",
    "        + expected sample size for completion, on the assumption that there are no errors\n",
    "        + 90th percentile of sample size for completion, on the assumption that errors are not more frequent than specified\n",
    "    - If `not use_style`: base estimate on sampling from the entire manifest, i.e., smallest assorter margin\n",
    "    - Else: use consistent sampling:\n",
    "        + Augment each CVR (including phantoms) with a probability of selection, `p`, initially 0\n",
    "        + For each contest `c`:\n",
    "            - Find sample size `n_c` that meets the criterion \n",
    "            - For each non-phantom CVR that contains the contest, set `p = max(p, n_c/N_c)` \n",
    "        + Estimated sample size is the sum of `p` over all non-phantom CVRs\n",
    "+ Draw the random sample:\n",
    "    - Use the specified design, including using consistent sampling for style information\n",
    "    - Express sample cards in terms of the manifest\n",
    "    - Export\n",
    "+ Read manual interpretations of the cards (MVRs)\n",
    "+ Calculate attained risk for each assorter\n",
    "    - Use ~2EZ to deal with phantom CVRs or cards; the treatment depends on whether `use_style == True`\n",
    "+ Report\n",
    "+ Estimate incremental sample size if any assorter nulls have not been rejected\n",
    "+ Draw incremental sample; etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audit parameters.\n",
    "\n",
    "The overall audit involves information that is the same across contests, encapsulated in\n",
    "a dict called `audit`:\n",
    "\n",
    "* `seed`: the numeric seed for the pseudo-random number generator used to draw sample (for SHA256 PRNG)\n",
    "* `sim_seed`: seed for simulations to estimate sample sizes (for Mersenne Twister PRNG)\n",
    "* `quantile`: quantile of the sample size to use for setting initial sample size\n",
    "* `cvr_file`: filename for CVRs (input)\n",
    "* `manifest_file`: filename for ballot manifest (input)\n",
    "* `use_style`: Boolean. If True, use card style information (inferred from CVRs) to target samples. If False, sample from all cards, regardless of the contest. This should come from external touchstones such as physical inventories or voter participation records, not from the voting system. In particualar, it is dangerous to assume that every card containing a contest has a corresponding CVR that contains the contest.\n",
    "* `sample_file`: filename for sampled card identifiers (output)\n",
    "* `mvr_file`: filename for manually ascertained votes from sampled cards (input)\n",
    "* `log_file`: filename for audit log (output)\n",
    "* `error_rate_1`: expected rate of 1-vote overstatements. Recommended value $\\ge$ 0.001 if there are hand-marked ballots. Larger values increase the initial sample size, but make it more likely that the audit will conclude after a single round even if the audit finds errors\n",
    "* `error_rate_2`: expected rate of 2-vote overstatements. 2-vote overstatements should be extremely rare.\n",
    "Recommended value: 0. Larger values increase the initial sample size, but make it more likely that the audit will conclude after a single round even if the audit finds errors\n",
    "* `reps`: number of replications to use to estimate sample sizes. If `reps is None`, uses a deterministic method\n",
    "* `quantile`: quantile of sample size to estimate. Not used if `reps is None`\n",
    "* `strata`: a dict describing the strata. Keys are stratum identifiers; values are dicts containing:\n",
    "    + `max_cards`: an upper bound on the number of pieces of paper cast in the contest. This should be derived independently of the voting system. A ballot consists of one or more cards.\n",
    "    + `replacement`: whether to sample from this stratum with replacement. \n",
    "    + `use_style`: True if the sample in that stratum uses card-style information.\n",
    "    + `audit_type` one of Contest.POLLING, Contest.CARD_COMPARISON, Contest.BATCH_COMPARISON but only POLLING and CARD_COMPARISON are currently implemented. \n",
    "    + `test`: the name of the function to be used to measure risk. Options are `kaplan_markov`,`kaplan_wald`,`kaplan_kolmogorov`,`wald_sprt`,`kaplan_mart`, `alpha_mart`, `betting_mart`. \n",
    "Not all risk functions work with every social choice function or every sampling method. \n",
    "    + `estim`: the estimator to be used by the `alpha_mart` risk function. Options:  \n",
    "        - `fixed_alternative_mean` (default)\n",
    "        - `shrink_trunc`\n",
    "        - `optimal_comparison`\n",
    "    + `bet`: the method to select the bet for the `betting_mart` risk function. Options:\n",
    "        - `fixed_bet` (default)\n",
    "        - `agrapa`\n",
    "    + `test_kwargs`: keyword arguments for the risk function\n",
    "\n",
    "----\n",
    "\n",
    "* `contests`: a dict of contest-specific data \n",
    "    + the keys are unique contest identifiers for contests under audit\n",
    "    + the values are Contest objects with attributes:\n",
    "        - `risk_limit`: the risk limit for the audit of this contest\n",
    "        - `cards`: an upper bound on the number of cast cards that contain the contest\n",
    "        - `choice_function`: `Audit.SOCIAL_CHOICE_FUNCTION.PLURALITY`, \n",
    "          `Audit.SOCIAL_CHOICE_FUNCTION.SUPERMAJORITY`, or `Audit.SOCIAL_CHOICE_FUNCTION.IRV`\n",
    "        - `n_winners`: number of winners for majority contests. (Multi-winner IRV, aka STV, is not supported)\n",
    "        - `share_to_win`: for super-majority contests, the fraction of valid votes required to win, e.g., 2/3.\n",
    "           (share_to_win*n_winners must be less than 100%)\n",
    "        - `candidates`: list of names or identifiers of candidates\n",
    "        - `reported_winners` : list of identifier(s) of candidate(s) reported to have won.\n",
    "           Length should equal `n_winners`.\n",
    "        - `assertion_file`: filename for a set of json descriptors of Assertions (see technical documentation) that collectively imply the reported outcome of the contest is correct. Required for IRV; ignored for other social choice functions\n",
    "        - `audit_type`: the audit strategy. Currently `Audit.AUDIT_TYPE.POLLING (ballot-polling)`, \n",
    "           `Audit.AUDIT_TYPE.CARD_COMPARISON` (ballot-level comparison audits), and `Audit.AUDIT_TYPE.ONEAUDIT`\n",
    "            are implemented. HYBRID and STRATIFIED are planned.\n",
    "        - `test`: the risk function for the audit. Default is `NonnegMean.alpha_mart`, the alpha supermartingale test\n",
    "        - `estim`: estimator for the alternative hypothesis for the test. Default is `NonnegMean.shrink_trunc`\n",
    "        - `use_style`: True to use style information from CVRs to target the sample. False for polling audits or for sampling from all ballots for every contest.\n",
    "        - other keys and values are added by the software, including `cvrs`, the number of CVRs that contain the contest, and `p`, the sampling fraction expected to be required to confirm the contest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if shangrla has not already been installed, install it then restart the kernel\n",
    "# !pip install -e \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import copy\n",
    "\n",
    "import glob\n",
    "import os, sys\n",
    "\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from cryptorandom.cryptorandom import SHA256, int_from_hash\n",
    "from cryptorandom.sample import sample_by_index\n",
    "\n",
    "from shangrla.core.Audit import Audit, Assertion, Assorter, Contest, CVR, Stratum\n",
    "from shangrla.core.NonnegMean import NonnegMean\n",
    "from shangrla.formats.Dominion import Dominion\n",
    "\n",
    "sys.path.append(os.path.realpath('./SHANGRLA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit = Audit.from_dict({\n",
    "         'seed':           12345678901234567890,\n",
    "         'sim_seed':       314159265,\n",
    "         'cvr_file':       './data/SF_CVR_Export_20240311150227/CvrExport_*.json',\n",
    "         'manifest_file':  './data/SF_CVR_Export_20240311150227/ballotManifest-dummy.xlsx',\n",
    "         'sample_file':    './data/SF_CVR_Export_20240311150227/sample.csv',\n",
    "         'mvr_file':       './data/SF_CVR_Export_20240311150227/mvr.json',\n",
    "         'log_file':       './data/SF_CVR_Export_20240311150227/log.json',\n",
    "         'quantile':       0.8,\n",
    "         'error_rate_1':   0.001,\n",
    "         'error_rate_2':   0.0,\n",
    "         'reps':           100,\n",
    "         'strata':         {'stratum_1': {'max_cards':   443578, \n",
    "                                          'use_style':   True,\n",
    "                                          'replacement': False,\n",
    "                                          'audit_type':  Audit.AUDIT_TYPE.ONEAUDIT,\n",
    "                                          'test':        NonnegMean.alpha_mart,\n",
    "                                          'estimator':   NonnegMean.optimal_comparison,\n",
    "                                          'test_kwargs': {}\n",
    "                                         }\n",
    "                           }\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443578"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find upper bound on total cards across strata\n",
    "audit.max_cards = np.sum([s.max_cards for s in audit.strata.values()])\n",
    "audit.max_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contests to audit. Edit with details of your contest \n",
    "contest_dict = {\n",
    "               '1':{\n",
    "                   'name': 'PRESIDENT OF THE UNITED STATES-DEM',\n",
    "                   'risk_limit':       0.05,\n",
    "                   'cards': 152649,\n",
    "                   'choice_function':  Contest.SOCIAL_CHOICE_FUNCTION.PLURALITY,\n",
    "                   'n_winners': 1,\n",
    "                   'candidates': ['1','2','3','4','5','6','7','8'],\n",
    "                   'winner': ['5'],\n",
    "                   'assertion_file':   None,\n",
    "                   'audit_type':       Audit.AUDIT_TYPE.ONEAUDIT,\n",
    "                   'test':             NonnegMean.alpha_mart,\n",
    "                   'estim':            NonnegMean.optimal_comparison\n",
    "                  },\n",
    "               '2':{\n",
    "                   'name':            'PRESIDENT OF THE UNITED STATES-REP',\n",
    "                   'risk_limit':       0.05,\n",
    "                   'cards':            15591,\n",
    "                   'choice_function':  Contest.SOCIAL_CHOICE_FUNCTION.PLURALITY,\n",
    "                   'n_winners':        1,\n",
    "                   'candidates': ['10','11','12','13','14','15','16','17','9'],\n",
    "                   'winner': ['11'],\n",
    "                   'assertion_file':   None,\n",
    "                   'audit_type':       Audit.AUDIT_TYPE.ONEAUDIT,\n",
    "                   'test':             NonnegMean.alpha_mart,\n",
    "                   'estim':            NonnegMean.optimal_comparison\n",
    "                  }\n",
    "               }\n",
    "\n",
    "contests = Contest.from_dict_of_dicts(contest_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the assertions for the IRV contest\n",
    "for c in contests:\n",
    "    if contests[c].choice_function == Contest.SOCIAL_CHOICE_FUNCTION.IRV:\n",
    "        with open(contests[c].assertion_file, 'r') as f:\n",
    "            contests[c].assertion_json = json.load(f)['audits'][0]['assertions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct the dict of dicts of assertions for each contest\n",
    "Assertion.make_all_assertions(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audit.check_audit_parameters(contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the ballot manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special for Primary/Dominion manifest format\n",
    "manifest = pd.read_excel(audit.manifest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CVR data and create CVR objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ballot-level comparison audits\n",
    "cvr_list = []\n",
    "for _fname in glob.glob(audit.cvr_file):\n",
    "    cvr_list.extend(Dominion.read_cvrs(_fname, use_current=True, enforce_rules=True, include_groups=[1,2],\n",
    "                                      pool_groups=[1]))\n",
    "    \n",
    "cvr_list = Dominion.raire_to_dominion(cvr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvrs: 443578 unique IDs: 443578\n"
     ]
    }
   ],
   "source": [
    "# check that the CVR IDs are unique\n",
    "unique_ids = len(set(c.id for c in cvr_list))\n",
    "print(f'cvrs: {len(cvr_list)} unique IDs: {unique_ids}')\n",
    "assert unique_ids == len(cvr_list), 'CVR IDs are not unique'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lexicographic position in batch to CVRs from polling places, where actual position is unknown\n",
    "_ = CVR.set_card_in_batch_lex(cvr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(443578, 443578)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double-check whether the manifest accounts for every card\n",
    "audit.max_cards, np.sum(manifest['Total Ballots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tray #</th>\n",
       "      <th>Tabulator Number</th>\n",
       "      <th>Batch Number</th>\n",
       "      <th>Total Ballots</th>\n",
       "      <th>VBMCart.Cart number</th>\n",
       "      <th>cum_cards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>267</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>919</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>287</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>204</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6437</th>\n",
       "      <td>6437</td>\n",
       "      <td>6438</td>\n",
       "      <td>11</td>\n",
       "      <td>191</td>\n",
       "      <td>22</td>\n",
       "      <td>6438</td>\n",
       "      <td>443224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>6438</td>\n",
       "      <td>6439</td>\n",
       "      <td>1023</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>6439</td>\n",
       "      <td>443342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6439</th>\n",
       "      <td>6439</td>\n",
       "      <td>6440</td>\n",
       "      <td>13</td>\n",
       "      <td>202</td>\n",
       "      <td>75</td>\n",
       "      <td>6440</td>\n",
       "      <td>443417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6440</th>\n",
       "      <td>6440</td>\n",
       "      <td>6441</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>147</td>\n",
       "      <td>6441</td>\n",
       "      <td>443564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6441</th>\n",
       "      <td>6441</td>\n",
       "      <td>6442</td>\n",
       "      <td>12</td>\n",
       "      <td>442</td>\n",
       "      <td>14</td>\n",
       "      <td>6442</td>\n",
       "      <td>443578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6442 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Tray # Tabulator Number Batch Number  Total Ballots  \\\n",
       "0              0      1                1          267             68   \n",
       "1              1      2              919            0             98   \n",
       "2              2      3                6          287              4   \n",
       "3              3      4                2           86             83   \n",
       "4              4      5               12          204             91   \n",
       "...          ...    ...              ...          ...            ...   \n",
       "6437        6437   6438               11          191             22   \n",
       "6438        6438   6439             1023            0            118   \n",
       "6439        6439   6440               13          202             75   \n",
       "6440        6440   6441               12           39            147   \n",
       "6441        6441   6442               12          442             14   \n",
       "\n",
       "     VBMCart.Cart number  cum_cards  \n",
       "0                      1         68  \n",
       "1                      2        166  \n",
       "2                      3        170  \n",
       "3                      4        253  \n",
       "4                      5        344  \n",
       "...                  ...        ...  \n",
       "6437                6438     443224  \n",
       "6438                6439     443342  \n",
       "6439                6440     443417  \n",
       "6440                6441     443564  \n",
       "6441                6442     443578  \n",
       "\n",
       "[6442 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that there is a card in the manifest for every card (possibly) cast. If not, add phantoms.\n",
    "manifest, manifest_cards, phantom_cards = Dominion.prep_manifest(manifest, audit.max_cards, len(cvr_list))\n",
    "manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CVRs for phantom cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 0 phantom records\n"
     ]
    }
   ],
   "source": [
    "# For Comparison Audits (including ONEAudit) Only\n",
    "#----------------------------\n",
    "\n",
    "# If the sample draws a phantom card, these CVRs will be used in the comparison.\n",
    "# phantom MVRs should be treated as zeros by the Assorter for every contest\n",
    "\n",
    "# setting use_style = False to generate phantoms\n",
    "\n",
    "cvr_list, phantom_vrs = CVR.make_phantoms(audit=audit, contests=contests, cvr_list=cvr_list, prefix='phantom-1-')\n",
    "print(f\"Created {phantom_vrs} phantom records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum assorter margin 0.29034022535827586\n",
      "margins in contest 1:\n",
      "\tassertion 5 v 4: 0.8080522680693274\n",
      "\tassertion 5 v 8: 0.8100366066034048\n",
      "\tassertion 5 v 1: 0.8077916385305233\n",
      "\tassertion 5 v 7: 0.7808342514601179\n",
      "\tassertion 5 v 3: 0.8068083543613984\n",
      "\tassertion 5 v 2: 0.8096041985049343\n",
      "\tassertion 5 v 6: 0.7784885856108801\n",
      "margins in contest 2:\n",
      "\tassertion 11 v 14: 0.5938081172738212\n",
      "\tassertion 11 v 10: 0.5942457061590636\n",
      "\tassertion 11 v 13: 0.59451919921234\n",
      "\tassertion 11 v 16: 0.575976370200197\n",
      "\tassertion 11 v 12: 0.5804616562739306\n",
      "\tassertion 11 v 9: 0.29034022535827586\n",
      "\tassertion 11 v 17: 0.5850016409583196\n",
      "\tassertion 11 v 15: 0.594683295044306\n"
     ]
    }
   ],
   "source": [
    "# find the mean of the assorters for the CVRs and check whether the assertions are met\n",
    "min_margin = Assertion.set_all_margins_from_cvrs(audit=audit, contests=contests, cvr_list=cvr_list)\n",
    "\n",
    "print(f'minimum assorter margin {min_margin}')\n",
    "Contest.print_margins(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit.write_audit_parameters(contests=contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ONEAudit Assorter means for each assertion for each tally pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pools = set(c.tally_pool for c in cvr_list if c.pool)\n",
    "len(pools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443578"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure every CVR in each `tally_pool` has the same value of `pool`\n",
    "cvr_list = CVR.check_tally_pools(cvr_list)\n",
    "len(cvr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all contest IDs mentioned in the pooled CVRs\n",
    "tally_pool = {}\n",
    "for p in pools:\n",
    "    tally_pool[p] = CVR.pool_contests(list([c for c in cvr_list if c.tally_pool == p]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure every CVR in each `tally_pool` for which `pool == True` has every contest in the tally_pool\n",
    "CVR.add_pool_contests(cvr_list, tally_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pooled assorter means\n",
    "for con in contests.values():\n",
    "    for a in con.assertions.values():\n",
    "        a.assorter.set_tally_pool_means(cvr_list=cvr_list, tally_pool=pools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find initial sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_size=81\n",
      "[('1', 7), ('2', 20)]\n"
     ]
    }
   ],
   "source": [
    "# find initial sample size \n",
    "sample_size = audit.find_sample_size(contests, cvrs=cvr_list)  \n",
    "print(f'{sample_size=}\\n{[(i, c.sample_size) for i, c in contests.items()]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Draw the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw the initial sample using consistent sampling\n",
    "prng = SHA256(audit.seed)\n",
    "CVR.assign_sample_nums(cvr_list, prng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample includes 0 phantom cards.\n"
     ]
    }
   ],
   "source": [
    "sampled_cvr_indices = CVR.consistent_sampling(cvr_list=cvr_list, contests=contests)\n",
    "n_sampled_phantoms = np.sum(sampled_cvr_indices > manifest_cards)\n",
    "print(f'The sample includes {n_sampled_phantoms} phantom cards.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(443578, 443578, 443578)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cvr_list), manifest_cards, audit.max_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for comparison audit\n",
    "cards_to_retrieve, sample_order, cvr_sample, mvr_phantoms_sample = \\\n",
    "    Dominion.sample_from_cvrs(cvr_list, manifest, sampled_cvr_indices)\n",
    "\n",
    "# for polling audit\n",
    "# cards_to_retrieve, sample_order, mvr_phantoms_sample = Dominion.sample_from_manifest(manifest, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the sample\n",
    "if os.path.exists(audit.sample_file):\n",
    "    os.remove(audit.sample_file)\n",
    "    \n",
    "Dominion.write_cards_sampled(audit.sample_file, cards_to_retrieve, print_phantoms=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the audited sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for real data\n",
    "with open(audit.mvr_file) as f:\n",
    "    mvr_json = json.load(f)\n",
    "\n",
    "mvr_sample = CVR.from_dict(mvr_json['ballots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for simulated data, no errors\n",
    "mvr_sample = cvr_sample.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find measured risks for all assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVR.prep_comparison_sample(mvr_sample, cvr_sample, sample_order)  # for comparison audit\n",
    "# CVR.prep_polling_sample(mvr_sample, sample_order)  # for polling audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_max = Assertion.set_p_values(contests=contests, mvr_sample=mvr_sample, cvr_sample=cvr_sample)\n",
    "print(f'maximum assertion p-value {p_max}')\n",
    "done = audit.summarize_status(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the status of the audit \n",
    "audit.write_audit_parameters(contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many more cards should be audited?\n",
    "\n",
    "Estimate how many more cards will need to be audited to confirm any remaining contests. The enlarged sample size is based on:\n",
    "\n",
    "* cards already sampled\n",
    "* the assumption that we will continue to see errors at the same rate observed in the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate sample size required to confirm the outcome, if errors continue\n",
    "# at the same rate as already observed.\n",
    "\n",
    "new_size = audit.find_sample_size(contests, cvrs=cvr_list, mvr_sample=mvr_sample, cvr_sample=cvr_sample)\n",
    "print(f'{new_size=}\\n{[(i, c.sample_size) for i, c in contests.items()]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the first sample\n",
    "sampled_cvr_indices_old, cards_to_retrieve_old, sample_order_old, cvr_sample_old, mvr_phantoms_sample_old = \\\n",
    "    sampled_cvr_indices, cards_to_retrieve,     sample_order,     cvr_sample,     mvr_phantoms_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the sample\n",
    "sampled_cvr_indices = CVR.consistent_sampling(cvr_list=cvr_list, contests=contests)\n",
    "n_sampled_phantoms = np.sum(sampled_cvr_indices > manifest_cards)\n",
    "print(f'The sample includes {n_sampled_phantoms} phantom cards.')\n",
    "\n",
    "# for comparison audit\n",
    "cards_to_retrieve, sample_order, cvr_sample, mvr_phantoms_sample = \\\n",
    "    Dominion.sample_from_cvrs(cvr_list, manifest, sampled_cvr_indices)\n",
    "\n",
    "# for polling audit\n",
    "# cards_to_retrieve, sample_order, mvr_phantoms_sample = Dominion.sample_from_manifest(manifest, sample)\n",
    "\n",
    "# write the sample\n",
    "# could write only the incremental sample using list(set(cards_to_retrieve) - set(cards_to_retrieve_old))\n",
    "Dominion.write_cards_sampled(audit.sample_file, cards_to_retrieve, print_phantoms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for real data\n",
    "with open(audit.mvr_file) as f:\n",
    "    mvr_json = json.load(f)\n",
    "\n",
    "mvr_sample = CVR.from_dict(mvr_json['ballots'])\n",
    "\n",
    "# for simulated data, no errors\n",
    "mvr_sample = cvr_sample.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find measured risks for all assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVR.prep_comparison_sample(mvr_sample, cvr_sample, sample_order)  # for comparison audit\n",
    "# CVR.prep_polling_sample(mvr_sample, sample_order)  # for polling audit\n",
    "\n",
    "###### TEST\n",
    "# permute part of the sample to introduce errors deliberately\n",
    "mvr_sample = cvr_sample.copy()\n",
    "n_errs = 5\n",
    "errs = mvr_sample[0:n_errs].copy()\n",
    "np.random.seed(12345678)\n",
    "np.random.shuffle(errs)\n",
    "mvr_sample[0:n_errs] = errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_max = Assertion.set_p_values(contests=contests, mvr_sample=mvr_sample, cvr_sample=cvr_sample)\n",
    "print(f'maximum assertion p-value {p_max}')\n",
    "done = audit.summarize_status(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "state": {
    "6cab9cab294247839758fa9e8d64d122": {
     "views": [
      {
       "cell_index": 42
      }
     ]
    },
    "b7b0321f834d45ebb1bdc036fba7a916": {
     "views": [
      {
       "cell_index": 38
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
